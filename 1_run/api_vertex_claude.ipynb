{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 315,
          "status": "ok",
          "timestamp": 1714565834120,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "s6SJn92__jpy"
      },
      "outputs": [],
      "source": [
        "# 240630\n",
        "\n",
        "from glob import glob\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from itertools import product\n",
        "from anthropic import AnthropicVertex\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from format import *\n",
        "\n",
        "REGION = 'us-east5'\n",
        "PROJECT_ID = \"phonic-impact-421908\"\n",
        "ENDPOINT = f\"https://{REGION}-aiplatform.googleapis.com\"\n",
        "\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
        "client = AnthropicVertex(region=REGION, project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 303,
          "status": "ok",
          "timestamp": 1714565869342,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "j0nQk_dO-xa4"
      },
      "outputs": [],
      "source": [
        "class ModelResponder:\n",
        "    def __init__(self, model_path, ques_path_list, context_list, prompt_func_list=None, path=None):\n",
        "        self.batch_size = 100\n",
        "        self.model_path = model_path\n",
        "        if path is not None:\n",
        "            self.path = path\n",
        "        else:\n",
        "            self.path = os.path.basename(model_path)\n",
        "\n",
        "        if not prompt_func_list:\n",
        "            default_prompt_func = lambda inst,ques: f\"{ques}\"\n",
        "            prompt_func_list = [default_prompt_func]\n",
        "        self.prompt_func_list = prompt_func_list\n",
        "\n",
        "        indexed_ques_paths = list(enumerate(ques_path_list))\n",
        "        indexed_prompt_funcs = list(enumerate(self.prompt_func_list))\n",
        "        indexed_contexts = list(enumerate(context_list))\n",
        "        self.combinations = list(product(indexed_ques_paths, indexed_prompt_funcs, indexed_contexts))\n",
        "\n",
        "    def process_and_update(self, ques_dict, context, prompt_func, pbar):\n",
        "        max_retries = 50\n",
        "        retries = 0\n",
        "        ques=ques_dict['input']\n",
        "        while retries < max_retries:\n",
        "            try:\n",
        "                responses = client.messages.create(\n",
        "                    messages=[{\"role\":\"user\",\"content\": ques}],\n",
        "                    system=context,\n",
        "                    model=self.model_path,\n",
        "                    temperature=0,\n",
        "                    max_tokens=1024\n",
        "                )\n",
        "                output = responses.to_dict()['content'][0]['text']\n",
        "                ques_dict['response'] = output\n",
        "                pbar.update(1)\n",
        "                return ques_dict\n",
        "            except Exception as e:\n",
        "                current = f\"{ques_dict['year']}-{ques_dict['session']}-{ques_dict['question_number']}\"\n",
        "                if \"Quota\" or \"quota\" in str(e):\n",
        "                    time.sleep(60)\n",
        "                else:\n",
        "                    retries += 1\n",
        "                    print(e)\n",
        "                    print(f\"Retrying '{current}'... {retries}/{max_retries}\")\n",
        "                    time.sleep(10)\n",
        "                if retries == max_retries:\n",
        "                    print(f\"Failed to generate response for '{current}', skipping...\")\n",
        "                    ques_dict['response'] = None\n",
        "                    return ques_dict\n",
        "\n",
        "    def process_files(self):\n",
        "        for (ques_idx, ques_path), (prompt_idx, prompt_func), (context_idx, inst) in self.combinations:\n",
        "            with open(ques_path) as f:\n",
        "                exam = json.load(f)\n",
        "            filename=f'output/{self.path} [f{prompt_idx+1}_p{context_idx+1}_q{ques_idx+1}].json'\n",
        "            dataset = ExamDataset(exam, inst, prompt_func)\n",
        "            dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
        "            with tqdm(total=len(dataloader),desc=filename, leave=True, position=1) as pbar:\n",
        "                for i, batch in enumerate(dataloader):\n",
        "                    with ThreadPoolExecutor() as executor:\n",
        "                        with tqdm(total=len(batch), desc=f\"Batch {i}\", leave=True, position=0) as batch_pbar:\n",
        "                            results = list(executor.map(lambda ques: self.process_and_update(ques, inst, prompt_func, batch_pbar), batch))\n",
        "                    if os.path.exists(filename):\n",
        "                        with open(filename, 'r') as file:\n",
        "                            resp = json.load(file)\n",
        "                    else:\n",
        "                        resp = []\n",
        "                        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "                    for result in results:\n",
        "                        resp.append(result)\n",
        "                    with open(filename, 'w', encoding='utf-8') as f:\n",
        "                        json.dump(resp, f, indent=4, ensure_ascii=False)\n",
        "                    pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 0: 100%|██████████| 100/100 [00:14<00:00,  6.78it/s]        | 0/21 [00:00<?, ?it/s]\n",
            "Batch 1: 100%|██████████| 100/100 [00:09<00:00, 10.97it/s]        | 1/21 [00:14<04:54, 14.75s/it]\n",
            "Batch 2: 100%|██████████| 100/100 [00:09<00:00, 11.00it/s]        | 2/21 [00:23<03:37, 11.44s/it]\n",
            "Batch 3: 100%|██████████| 100/100 [00:09<00:00, 10.65it/s]        | 3/21 [00:32<03:06, 10.37s/it]\n",
            "Batch 4: 100%|██████████| 100/100 [00:10<00:00,  9.85it/s]        | 4/21 [00:42<02:49,  9.99s/it]\n",
            "Batch 5: 100%|██████████| 100/100 [00:08<00:00, 11.38it/s]▍       | 5/21 [00:52<02:40, 10.05s/it]\n",
            "Batch 6: 100%|██████████| 100/100 [00:10<00:00,  9.95it/s]▊       | 6/21 [01:01<02:24,  9.63s/it]\n",
            "Batch 7: 100%|██████████| 100/100 [00:08<00:00, 11.55it/s]█▎      | 7/21 [01:11<02:16,  9.77s/it]\n",
            "Batch 8: 100%|██████████| 100/100 [00:09<00:00, 11.02it/s]█▊      | 8/21 [01:20<02:02,  9.42s/it]\n",
            "Batch 9: 100%|██████████| 100/100 [00:09<00:00, 10.64it/s]██▎     | 9/21 [01:29<01:51,  9.32s/it]\n",
            "Batch 10: 100%|██████████| 100/100 [00:09<00:00, 10.70it/s]█▊     | 10/21 [01:38<01:42,  9.35s/it]\n",
            "Batch 11: 100%|██████████| 100/100 [00:11<00:00,  8.43it/s]██▏    | 11/21 [01:47<01:33,  9.36s/it]\n",
            "Batch 12: 100%|██████████| 100/100 [00:09<00:00, 11.03it/s]██▋    | 12/21 [01:59<01:31, 10.13s/it]\n",
            "Batch 13: 100%|██████████| 100/100 [00:09<00:00, 10.93it/s]███▏   | 13/21 [02:08<01:18,  9.82s/it]\n",
            "Batch 14: 100%|██████████| 100/100 [00:09<00:00, 11.02it/s]███▋   | 14/21 [02:18<01:07,  9.62s/it]\n",
            "Batch 15: 100%|██████████| 100/100 [00:10<00:00,  9.76it/s]████▏  | 15/21 [02:27<00:56,  9.47s/it]\n",
            "Batch 16: 100%|██████████| 100/100 [00:09<00:00, 10.79it/s]████▌  | 16/21 [02:37<00:48,  9.71s/it]\n",
            "Batch 17: 100%|██████████| 100/100 [00:09<00:00, 10.46it/s]█████  | 17/21 [02:46<00:38,  9.59s/it]\n",
            "Batch 18: 100%|██████████| 100/100 [00:11<00:00,  8.98it/s]█████▌ | 18/21 [02:56<00:28,  9.59s/it]\n",
            "Batch 19: 100%|██████████| 100/100 [00:08<00:00, 11.20it/s]██████ | 19/21 [03:07<00:20, 10.07s/it]\n",
            "Batch 20: 100%|██████████| 100/100 [00:09<00:00, 10.97it/s]██████▌| 20/21 [03:16<00:09,  9.74s/it]\n",
            "output/claude-3-5-sonnet@20240620 [f1_p1_q1].json: 100%|██████████| 21/21 [03:25<00:00,  9.80s/it]\n",
            "Batch 0: 100%|██████████| 100/100 [00:09<00:00, 11.09it/s]        | 0/21 [00:00<?, ?it/s]\n",
            "Batch 1: 100%|██████████| 100/100 [00:08<00:00, 11.43it/s]        | 1/21 [00:09<03:00,  9.02s/it]\n",
            "Batch 2: 100%|██████████| 100/100 [00:08<00:00, 11.30it/s]        | 2/21 [00:17<02:48,  8.87s/it]\n",
            "Batch 3: 100%|██████████| 100/100 [00:08<00:00, 12.06it/s]        | 3/21 [00:26<02:39,  8.86s/it]\n",
            "Batch 4: 100%|██████████| 100/100 [00:08<00:00, 11.33it/s]        | 4/21 [00:34<02:26,  8.64s/it]\n",
            "Batch 5: 100%|██████████| 100/100 [00:09<00:00, 11.02it/s]▍       | 5/21 [00:43<02:19,  8.71s/it]\n",
            "Batch 6: 100%|██████████| 100/100 [00:09<00:00, 10.72it/s]▊       | 6/21 [00:52<02:12,  8.84s/it]\n",
            "Batch 7: 100%|██████████| 100/100 [00:08<00:00, 11.26it/s]█▎      | 7/21 [01:02<02:06,  9.01s/it]\n",
            "Batch 8: 100%|██████████| 100/100 [00:09<00:00, 10.66it/s]█▊      | 8/21 [01:11<01:56,  8.97s/it]\n",
            "Batch 9: 100%|██████████| 100/100 [00:28<00:00,  3.47it/s]██▎     | 9/21 [01:20<01:49,  9.11s/it]\n",
            "Batch 10: 100%|██████████| 100/100 [00:09<00:00, 10.03it/s]█▊     | 10/21 [01:49<02:47, 15.20s/it]\n",
            "Batch 11: 100%|██████████| 100/100 [00:12<00:00,  8.28it/s]██▏    | 11/21 [01:59<02:16, 13.61s/it]\n",
            "Batch 12: 100%|██████████| 100/100 [00:08<00:00, 11.15it/s]██▋    | 12/21 [02:11<01:58, 13.15s/it]\n",
            "Batch 13: 100%|██████████| 100/100 [00:09<00:00, 10.71it/s]███▏   | 13/21 [02:20<01:35, 11.89s/it]\n",
            "Batch 14: 100%|██████████| 100/100 [00:09<00:00, 10.76it/s]███▋   | 14/21 [02:29<01:17, 11.13s/it]\n",
            "Batch 15: 100%|██████████| 100/100 [00:09<00:00, 10.60it/s]████▏  | 15/21 [02:39<01:03, 10.59s/it]\n",
            "Batch 16: 100%|██████████| 100/100 [00:09<00:00, 10.73it/s]████▌  | 16/21 [02:48<00:51, 10.25s/it]\n",
            "Batch 17: 100%|██████████| 100/100 [00:09<00:00, 10.28it/s]█████  | 17/21 [02:57<00:39,  9.98s/it]\n",
            "Batch 18: 100%|██████████| 100/100 [00:13<00:00,  7.32it/s]█████▌ | 18/21 [03:07<00:29,  9.92s/it]\n",
            "Batch 19: 100%|██████████| 100/100 [00:09<00:00, 10.25it/s]██████ | 19/21 [03:21<00:22, 11.06s/it]\n",
            "Batch 20: 100%|██████████| 100/100 [00:09<00:00, 10.53it/s]██████▌| 20/21 [03:31<00:10, 10.68s/it]\n",
            "output/claude-3-5-sonnet@20240620 [f1_p1_q2].json: 100%|██████████| 21/21 [03:40<00:00, 10.52s/it]\n"
          ]
        }
      ],
      "source": [
        "model_path = \"claude-3-5-sonnet@20240620\"\n",
        "run = ModelResponder(model_path, exam_list, inst_list)\n",
        "run.process_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7695873,
          "status": "ok",
          "timestamp": 1714573576069,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "b5QIP_FyAt1U",
        "outputId": "66ad1046-94ca-4683-d46c-1ada9e0182d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 0:   0%|          | 0/100 [00:00<?, ?it/s] 0%|          | 0/21 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 0: 100%|██████████| 100/100 [01:31<00:00,  1.10it/s]\n",
            "Batch 1: 100%|██████████| 100/100 [01:36<00:00,  1.03it/s]    | 1/21 [01:31<30:22, 91.14s/it]\n",
            "Batch 2: 100%|██████████| 100/100 [01:32<00:00,  1.08it/s]    | 2/21 [03:07<29:53, 94.37s/it]\n",
            "Batch 3: 100%|██████████| 100/100 [02:26<00:00,  1.47s/it]    | 3/21 [04:40<28:02, 93.49s/it]\n",
            "Batch 4: 100%|██████████| 100/100 [01:41<00:00,  1.02s/it]    | 4/21 [07:07<32:28, 114.61s/it]\n",
            "Batch 5: 100%|██████████| 100/100 [02:41<00:00,  1.61s/it]    | 5/21 [08:48<29:19, 109.95s/it]\n",
            "Batch 6: 100%|██████████| 100/100 [02:38<00:00,  1.59s/it]    | 6/21 [11:30<31:50, 127.36s/it]\n",
            "Batch 7: 100%|██████████| 100/100 [01:38<00:00,  1.02it/s]    | 7/21 [14:08<32:06, 137.60s/it]\n",
            "Batch 8: 100%|██████████| 100/100 [02:45<00:00,  1.66s/it]    | 8/21 [15:46<27:05, 125.01s/it]\n",
            "Batch 9: 100%|██████████| 100/100 [02:30<00:00,  1.50s/it]    | 9/21 [18:32<27:32, 137.72s/it]\n",
            "Batch 10: 100%|██████████| 100/100 [01:39<00:00,  1.01it/s]   | 10/21 [21:02<25:57, 141.56s/it]\n",
            "Batch 11: 100%|██████████| 100/100 [01:47<00:00,  1.07s/it]   | 11/21 [22:41<21:25, 128.55s/it]\n",
            "Batch 12: 100%|██████████| 100/100 [02:37<00:00,  1.57s/it]   | 12/21 [24:29<18:19, 122.11s/it]\n",
            "Batch 13: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]   | 13/21 [27:06<17:42, 132.84s/it]\n",
            "Batch 14: 100%|██████████| 100/100 [02:26<00:00,  1.47s/it]   | 14/21 [29:42<16:17, 139.70s/it]\n",
            "Batch 15: 100%|██████████| 100/100 [01:45<00:00,  1.06s/it]▏  | 15/21 [32:08<14:11, 141.85s/it]\n",
            "Batch 16: 100%|██████████| 100/100 [02:46<00:00,  1.66s/it]▌  | 16/21 [33:54<10:55, 131.06s/it]\n",
            "Batch 17: 100%|██████████| 100/100 [01:30<00:00,  1.10it/s]█  | 17/21 [36:41<09:26, 141.69s/it]\n",
            "Batch 18: 100%|██████████| 100/100 [01:52<00:00,  1.12s/it]█▌ | 18/21 [38:12<06:19, 126.41s/it]\n",
            "Batch 19: 100%|██████████| 100/100 [02:33<00:00,  1.54s/it]██ | 19/21 [40:04<04:04, 122.17s/it]\n",
            "Batch 20: 100%|██████████| 100/100 [01:39<00:00,  1.00it/s]██▌| 20/21 [42:38<02:11, 131.69s/it]\n",
            "output/claude-3-opus@20240229 [f1_p1_q1].json: 100%|██████████| 21/21 [44:18<00:00, 126.59s/it]\n",
            "Batch 0:  52%|█████▏    | 52/100 [01:17<00:11,  4.22it/s]     | 0/21 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-1-47'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-1-28'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-1-32'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 0:  57%|█████▋    | 57/100 [01:19<00:19,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-1-33'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 0:  64%|██████▍   | 64/100 [01:20<00:12,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-1-59'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-1-57'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-1-61'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 0: 100%|██████████| 100/100 [02:38<00:00,  1.59s/it]\n",
            "Batch 1:  50%|█████     | 50/100 [00:13<00:13,  3.81it/s]     | 1/21 [02:38<52:57, 158.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-2-47'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 1: 100%|██████████| 100/100 [01:33<00:00,  1.07it/s]\n",
            "Batch 2:  63%|██████▎   | 63/100 [01:20<00:20,  1.77it/s]     | 2/21 [04:12<38:03, 120.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-3-67'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 2:  66%|██████▌   | 66/100 [01:21<00:17,  1.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-3-68'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 2: 100%|██████████| 100/100 [02:30<00:00,  1.50s/it]\n",
            "Batch 3:  19%|█▉        | 19/100 [00:07<00:20,  4.00it/s]     | 3/21 [06:42<40:11, 133.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-4-40'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-4-46'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-4-50'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-4-49'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 3:  35%|███▌      | 35/100 [00:12<00:14,  4.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-4-71'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-4-70'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 3:  43%|████▎     | 43/100 [00:14<00:17,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2019-4-81'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 3: 100%|██████████| 100/100 [01:35<00:00,  1.05it/s]\n",
            "Batch 4:  61%|██████    | 61/100 [01:19<00:10,  3.68it/s]     | 4/21 [08:17<33:36, 118.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2020-2-3'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 4:  75%|███████▌  | 75/100 [01:24<00:10,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2020-2-22'... 1/50\n",
            "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
            "Retrying '2020-2-28'... 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 4: 100%|██████████| 100/100 [02:32<00:00,  1.52s/it]\n",
            "Batch 5: 100%|██████████| 100/100 [01:29<00:00,  1.12it/s]    | 5/21 [10:49<34:51, 130.70s/it]\n",
            "Batch 6: 100%|██████████| 100/100 [02:28<00:00,  1.48s/it]    | 6/21 [12:19<29:11, 116.75s/it]\n",
            "Batch 7: 100%|██████████| 100/100 [01:30<00:00,  1.10it/s]    | 7/21 [14:47<29:39, 127.10s/it]\n",
            "Batch 8: 100%|██████████| 100/100 [02:29<00:00,  1.50s/it]    | 8/21 [16:18<25:01, 115.54s/it]\n",
            "Batch 9: 100%|██████████| 100/100 [01:30<00:00,  1.10it/s]    | 9/21 [18:48<25:15, 126.25s/it]\n",
            "Batch 10: 100%|██████████| 100/100 [02:28<00:00,  1.48s/it]   | 10/21 [20:18<21:07, 115.23s/it]\n",
            "Batch 11: 100%|██████████| 100/100 [02:33<00:00,  1.53s/it]   | 11/21 [22:47<20:53, 125.37s/it]\n",
            "Batch 12: 100%|██████████| 100/100 [01:27<00:00,  1.14it/s]   | 12/21 [25:20<20:04, 133.85s/it]\n",
            "Batch 13: 100%|██████████| 100/100 [02:30<00:00,  1.51s/it]   | 13/21 [26:47<15:58, 119.84s/it]\n",
            "Batch 14: 100%|██████████| 100/100 [01:26<00:00,  1.16it/s]   | 14/21 [29:18<15:04, 129.16s/it]\n",
            "Batch 15: 100%|██████████| 100/100 [01:34<00:00,  1.06it/s]▏  | 15/21 [30:44<11:37, 116.24s/it]\n",
            "Batch 16: 100%|██████████| 100/100 [02:31<00:00,  1.52s/it]▌  | 16/21 [32:19<09:07, 109.58s/it]\n",
            "Batch 17: 100%|██████████| 100/100 [01:32<00:00,  1.08it/s]█  | 17/21 [34:50<08:09, 122.26s/it]\n",
            "Batch 18: 100%|██████████| 100/100 [01:35<00:00,  1.05it/s]█▌ | 18/21 [36:23<05:39, 113.29s/it]\n",
            "Batch 19: 100%|██████████| 100/100 [02:31<00:00,  1.51s/it]██ | 19/21 [37:58<03:35, 107.90s/it]\n",
            "Batch 20: 100%|██████████| 100/100 [01:17<00:00,  1.29it/s]██▌| 20/21 [40:30<02:00, 120.98s/it]\n",
            "output/claude-3-opus@20240229 [f1_p1_q2].json: 100%|██████████| 21/21 [41:47<00:00, 119.41s/it]\n"
          ]
        }
      ],
      "source": [
        "model_path = \"claude-3-opus@20240229\"\n",
        "run = ModelResponder(model_path, exam_list, inst_list)\n",
        "run.process_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 0:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "model_path = \"claude-3-sonnet@20240229\"\n",
        "run = ModelResponder(model_path, exam_list, inst_list)\n",
        "run.process_files()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "anthropic_claude_3_intro4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
